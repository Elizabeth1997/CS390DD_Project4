{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project 4: Generative Adversarial Networks\n",
    "======\n",
    "In this project, you are expected to fill in the missing parts of a PyTorch implementation of the Deep Convolutional Generative Adversarial Network (DCGAN) [1] and test its performance on several datasets.<br>\n",
    "Please **read the instructions carefully**. We provide reference outputs for most tasks and we will judge your solution based on your code as well as on the quality of your output and similarity to our results.\n",
    "\n",
    "We will be using datasets with small images for this project, because high-resolution GANs take notoriously long to train.\n",
    "\n",
    "**References:**\n",
    "\n",
    "[1] [Radford, A., Metz, L. and Chintala, S., 2015. Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434.](https://arxiv.org/abs/1511.06434)\n",
    "\n",
    "[2] [MNIST dataset.](http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "[3] [FashionMNIST dataset.](https://github.com/zalandoresearch/fashion-mnist)\n",
    "\n",
    "[4] [UTKFace dataset.](https://susanqq.github.io/UTKFace/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4A: DCGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify your PyTorch installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# Print Basic Information\n",
    "print('Torch', torch.__version__, 'CUDA', torch.version.cuda)\n",
    "print(\"Torchvision\", torchvision.__version__)\n",
    "print('Device:', torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "import os, time\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pickle\n",
    "import imageio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load and prepare the dataset (5 points)\n",
    "\n",
    "Pick either _MNIST_ [2] or _FashionMNIST_ [3] as your dataset for this assignment. Both datasets contain grayscale images with a natural resolution of $28\\times28$ pixels, have 10 classes and can be imported from `torchvision.datasets`.<br>\n",
    "The color channels in the _MNIST_ as well as in _FashionMNIST_ dataset are stored inverted, ie with white content on a black background. This is because, per default, convolution layers in the network add zero-padding to the image, hence a black background works more naturally and yields better results during training.\n",
    "We do, however, want to show our results with **black content** on a **white background**. To that end, **add appropriate functionality** in the plotting/visualization functions throughout this notebook to invert and clamp the image values (see below visualization).\n",
    "\n",
    "<img src=\"img/mnist_example.JPG\" width=\"800\">\n",
    "<img src=\"img/fashion_mnist_example.JPG\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the data loading, create the necessary **data transforms** such that your training images have $32\\times32$ pixels, and have a value range between $[-1, 1]$:\n",
    "\n",
    "Consider whether you can implement some **data augmentation**, and if possible, do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "# TODO 1: Load dataset. Implement the necessary functions so your data has a resolution of 32x32 pixels\n",
    "# and the values are normalized to a [-1, 1] range. \n",
    "# Consider whether you can implement some data augmentation, and if possible, do so.\n",
    "#######################################################################################################\n",
    "train_dataset = None\n",
    "\n",
    "print(\"Dataset length: \", len(train_dataset))\n",
    "print(\"Image size: {}\".format(train_dataset[0][0].size()))\n",
    "print(\"value range: [ {} - {} ]\".format(torch.min(train_dataset[0][0]), torch.max(train_dataset[0][0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the training data\n",
    "\n",
    "**Visualize a few examples** from your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_dataset.classes\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "rows = 6\n",
    "\n",
    "images = {}\n",
    "for label in range(len(labels)):\n",
    "    images[label] = []\n",
    "\n",
    "#find some images for each label    \n",
    "for x in range(1000):\n",
    "    rand = np.random.randint(len(train_dataset))\n",
    "    label = train_dataset[rand][1]\n",
    "    if len(images[label]) > rows:\n",
    "        continue\n",
    "    images[label].append(train_dataset[rand][0][0,:,:])\n",
    "    \n",
    "for label in range(len(labels)):\n",
    "    for row in range(rows):\n",
    "        image = images[label][row]\n",
    "        fig.add_subplot(rows, len(labels), row * len(labels) + label + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        if row == 0:\n",
    "            plt.title(labels[label])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Choose appropriate hyperparameters for the training (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "# TODO 2: choose sensible training parameters for DCGAN training. \n",
    "# Start with few epochs while you design the network, and increase once you think you have a good setup.\n",
    "# Since GANs train slowly, you may have to use at quite a few epochs to see good results.\n",
    "#######################################################################################################\n",
    "batch_size = 0 \n",
    "lr = 0\n",
    "num_epochs = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Implement the generator network (8 points)\n",
    "The expected output of this GAN should look like this (or better):\n",
    "\n",
    "<img src=\"img/DCGAN_MNIST.png\" align='left' width=\"355\">\n",
    "<img src=\"img/DCGAN_fashionMNIST.png\" align='left' width=\"355\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the **DCGAN Generator** and **Discriminator** networks for an output size of $32\\times32$ pixels according to the given network diagrams. \n",
    "\n",
    "<img src=\"img/DCGAN_generator.png\" align='left' width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to initialize the weights for `nn.Conv2d` and `nn.ConvTranspose2d` layers with a custom distribution. To that end, complete the function `normal_init`, which initialized the weights of the given pytorch layer with a Normal distribution centered around $mean$ and a standard deviation $std$.\n",
    "\n",
    "##### Hint: \n",
    "`summary` from the `torchsummary` package is a very helpful tool to inspect the layers in your network. Use it like so:\n",
    "\n",
    "```\n",
    "M = MyNetwork()\n",
    "M.cuda()\n",
    "summary(M, input_size=myExpectedInputSize)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "# TODO 3a: implement a function that initializes the layer's weights with mean and standard deviation.\n",
    "#######################################################################################################\n",
    "\n",
    "def normal_init(layer, mean, std):\n",
    "    pass # TODO add your implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "# TODO 3b: implement the generator network for a DCGAN with output size 32x32px\n",
    "#######################################################################################################\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        pass # TODO add your implementation\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, input):\n",
    "        return None # TODO add your implementation\n",
    "    \n",
    "    # weight_init\n",
    "    def weight_init(self, mean, std):\n",
    "        pass # TODO add your implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Implement the discriminator network (8 points)\n",
    "<img src=\"img/DCGAN_discriminator.png\" align='left' width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "# TODO 3c: implement the discriminator network for a DCGAN with input size 32x32px\n",
    "#######################################################################################################\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        pass # TODO add your implementation\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, input):\n",
    "        return None # TODO add your implementation\n",
    "    \n",
    "    # weight_init\n",
    "    def weight_init(self, mean, std):\n",
    "        pass # TODO add your implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 6\n",
    "\n",
    "#######################################################################################################\n",
    "# TODO 4: generate a fixed noise vector to repeatedly evaluate the output of the generator \n",
    "# with the same noise vector as training progresses\n",
    "#######################################################################################################\n",
    "fixed_z = None\n",
    "\n",
    "# output generated samples from the current state of the generator network\n",
    "def show_result(num_epoch, show=False, save=False, grid_size=6, path = 'result.png', useFixed=False):\n",
    "    with torch.no_grad():\n",
    "        if useFixed:   \n",
    "            fake = G(fixed_z).cpu()\n",
    "        else:\n",
    "            # TODO generate a new random noise vector\n",
    "            z = None\n",
    "            fake = G(z).cpu()\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        \n",
    "        image = utils.make_grid(fake.data, grid_size, 1)\n",
    "        \n",
    "        plt.imshow(np.transpose(image, (1, 2, 0)))    \n",
    "        ax.axis('off')\n",
    "        plt.savefig(path)\n",
    "        if show:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "\n",
    "# plot the losses over time as a curve            \n",
    "def plot_losses(hist, show=True, save=False, path='progress.png'):\n",
    "    x = range(len(hist['D_losses']))\n",
    "\n",
    "    y1 = hist['D_losses']\n",
    "    y2 = hist['G_losses']\n",
    "\n",
    "    plt.plot(x, y1, label='D_loss')\n",
    "    plt.plot(x, y2, label='G_loss')\n",
    "\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.legend(loc=4)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(path)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Training Setup (5 points) and Training Loop (10 points)\n",
    "\n",
    "Instantiate a Generator and a Discriminator network, move networks to GPU and initialize the weights of their convolutional layers with $\\mu=0$ and $\\sigma=0.02$.\n",
    "\n",
    "Create an ADAM optimizer for the generator as well as the discriminator with your chosen learning rate. Use $\\beta_1=0.5$ and $\\beta_2=0.999$ as described in Section 4 of the paper.\n",
    "\n",
    "In the training loop, evaluate the output of the generator network on a random latent vector of length 100. Then, evaluate the performance of the discriminator on the generated images as well as the real image minibatch. Assign the real results the label $1$ (`torch.ones`) and the fake results the label $0$ (`torch.zeros`), then calculate the losses for each of these steps using Binary Cross Entropy loss.\n",
    "        \n",
    "\n",
    "#### Hint:\n",
    "If you would like to load a stored model for additional training or for evaluation, you can do it the following way:\n",
    "```\n",
    "M = MyNetwork() #instantiate the network\n",
    "checkpoint = torch.load(\"path_to_stored_network.pkl\")\n",
    "M.load_state_dict(checkpoint)\n",
    "M.eval()\n",
    "``` \n",
    "\n",
    "*If your model fails to train properly, include the failure cases into your report, explain what you think went wrong, and try again!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dset_name = 'myDataset' #pick a meaningful name\n",
    "result_dir = '{}_DCGAN'.format(dset_name)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "\n",
    "#######################################################################################################\n",
    "# TODO 5a: Fill code for training setup\n",
    "#######################################################################################################\n",
    "\n",
    "# define networks\n",
    "G = None\n",
    "D = None\n",
    "\n",
    "# define optimizers\n",
    "G_optimizer = None\n",
    "D_optimizer = None \n",
    "\n",
    "# results save folder\n",
    "if not os.path.isdir(result_dir):\n",
    "    os.mkdir(result_dir)\n",
    "if not os.path.isdir(result_dir+'/Random'):\n",
    "    os.mkdir(result_dir+'/Random')\n",
    "if not os.path.isdir(result_dir+'/Fixed'):\n",
    "    os.mkdir(result_dir+'/Fixed')\n",
    "\n",
    "progress = {}\n",
    "progress['D_losses'] = []\n",
    "progress['G_losses'] = []\n",
    "progress['per_epoch_times'] = []\n",
    "progress['total_time'] = []\n",
    "num_iter = 0\n",
    "\n",
    "# start training loop\n",
    "print('Training ...')\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    D_losses = []\n",
    "    G_losses = []\n",
    "    \n",
    "    epoch_start_time = time.time()\n",
    "    for real, _ in data_loader:\n",
    "        real = real.to(device)\n",
    "        batch_size = real.size(0)\n",
    "        \n",
    "        #######################################################################################################\n",
    "        # TODO 5b: Fill code for training loop\n",
    "        #######################################################################################################\n",
    "        \n",
    "        # generate random latent vector z and real and fake labels \n",
    "    \n",
    "        # TODO \n",
    "        \n",
    "        # generate fakes    \n",
    "\n",
    "        # TODO \n",
    "        \n",
    "        # evaluate fakes\n",
    "        \n",
    "        # TODO \n",
    "\n",
    "        # evaluate real minibatch\n",
    "         \n",
    "        # TODO\n",
    "        \n",
    "        # accumulate discriminator loss from the information about the real and fake images it just saw\n",
    "        D_train_loss = None\n",
    "\n",
    "        # train discriminator D step\n",
    "        D.zero_grad()\n",
    "        D_train_loss.backward()\n",
    "        D_optimizer.step()    \n",
    "        \n",
    "        # train generator to output an image that is classified as real              \n",
    "        G_train_loss = None  \n",
    "        \n",
    "        # train generator G step\n",
    "        G.zero_grad()\n",
    "        G_train_loss.backward()\n",
    "        G_optimizer.step()              \n",
    "\n",
    "        D_losses.append(D_train_loss.data.item())\n",
    "        G_losses.append(G_train_loss.data.item())\n",
    "\n",
    "        num_iter += 1\n",
    "\n",
    "    epoch_end_time = time.time()\n",
    "    per_epoch_time = epoch_end_time - epoch_start_time\n",
    "    \n",
    "    print('Epoch [{} / {}] G loss: {} D loss: {}'.format(epoch + 1, num_epochs, G_train_loss, D_train_loss))\n",
    "\n",
    "    show_result( epoch, save=True, path=result_dir + '/Random/{}_DCGAN_{}.png'.format(dset_name, epoch), useFixed=False )\n",
    "    show_result( epoch, save=True, show=True, path=result_dir + '/Fixed/{}_DCGAN_{}.png'.format(dset_name, epoch), useFixed=True )\n",
    "    progress['D_losses'].append(torch.mean(torch.FloatTensor(D_losses)))\n",
    "    progress['G_losses'].append(torch.mean(torch.FloatTensor(G_losses)))\n",
    "    progress['per_epoch_times'].append(per_epoch_time)\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "progress['total_time'].append(total_time)\n",
    "\n",
    "print('Avg per epoch time: {:.2f} sec, total {:d} epochs time: {:.2f} min'.format(torch.mean(torch.FloatTensor(progress['per_epoch_times'])), num_epochs, total_time / 60))\n",
    "print('Training finished!')\n",
    "print('...saving training results')\n",
    "\n",
    "torch.save(G.state_dict(), result_dir + '/generator_network.pkl')\n",
    "torch.save(D.state_dict(), result_dir + '/discriminator_network.pkl')\n",
    "with open(result_dir + '/progress.pkl', 'wb') as f:\n",
    "    pickle.dump(progress, f)\n",
    "\n",
    "# plot the loss curves    \n",
    "plot_losses(progress, save=True, path=result_dir + '/{}_DCGAN_progress.png'.format(dset_name))\n",
    "\n",
    "# Visualize the training progress as an animated GIF\n",
    "images = []\n",
    "for e in range(num_epochs):\n",
    "    img_name = result_dir + '/Fixed/{}_DCGAN_{}.png'.format(dset_name, e)\n",
    "    images.append(imageio.imread(img_name))\n",
    "imageio.mimsave(result_dir + '/DCGAN_generation_animation.gif', images, fps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the animated generation GIF\n",
    "\n",
    "% **TODO: edit path to GIF** %\n",
    "\n",
    "<img src='full_path_to_gif.gif' width=\"512\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Explore the latent space of the generator (5 points)\n",
    "We now want to **explore the expressiveness** of the Generator. Intuitively, a small change in values of the latent vector $z$ should result in a small change in the output image, and a linear interpolation between two latent vectors $z_1$ and $z_2$ should yield a reasonably smooth transition from one valid output image to another. Implement a function that creates a grid of latent vectors, where each row is an interpolation from the leftmost to the rightmost latent vector, with $n$ interpolation steps.\n",
    "\n",
    "The expected output of this function should look like this (or better): \n",
    "\n",
    "\n",
    "<img src=\"img/latent_space_morph_MNIST.png\" width=\"900\">\n",
    "<img src=\"img/latent_space_morph_fashionMNIST.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_interpolation(rows=5, interp_steps=10):\n",
    "     with torch.no_grad():\n",
    "        #######################################################################################################\n",
    "        # TODO 6: for each row, create interpolation between leftmost and rightmost output image\n",
    "        #######################################################################################################\n",
    "        \n",
    "        # TODO \n",
    "        \n",
    "        grid_images = None\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(20, 10))\n",
    "        grid = utils.make_grid(grid_images, interp_steps)\n",
    "        plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
    "        ax.axis('off')\n",
    "\n",
    "generate_latent_interpolation()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Modify the network to output $64\\times64$ RGB images (10 points)\n",
    "\n",
    "Download `UTK_face.tar.gz` from [Google Drive](https://drive.google.com/drive/folders/0BxYys69jI14kU0I1YUQyY1ZDRUE) and extract the images to your working directory in the folder `./data/UTKFace/train`. This dataset [4] contains approximately 24K cropped images of human faces of mixed age, gender and race.\n",
    "\n",
    "Load these images and resize them to the dimensions you want to generate ($64\\times64$ RGB images). Replicate and modify your Generator and Discriminator network architectures in order to output the appropriate image size and three color channels. You may want to consult the [original DCGAN paper](https://arxiv.org/abs/1511.06434) to check what their suggested architecture looks like. You should generate an output similar to this (or better):\n",
    "\n",
    "<img src=\"img/DCGAN_faces.png\" width=\"900\">\n",
    "\n",
    "\n",
    "\n",
    "You can either modify the code above, or copy the necessary code pieces, but **make sure you include all results** of different datasets in your final report or in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "# TODO 7: resize the images such that they have the shape of 3x64x64\n",
    "#######################################################################################################\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "    root='./data/UTKFace'\n",
    ")\n",
    "\n",
    "print(\"Dataset length: \", len(train_dataset))\n",
    "print(\"Image size: {}\".format(train_dataset[0][0].size()))\n",
    "print(\"value range: [ {} - {} ]\".format(torch.min(train_dataset[0][0]), torch.max(train_dataset[0][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "# TODO 7: train a DCGAN on the face images\n",
    "#######################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Create a latent space walk of the Face Generator you trained (5 points)\n",
    "To that end, generate as many random latents as your animation has number of frames. Then, use a gaussian filter on those latents in order to create a smooth blending between adjacent frames in the animation. Have a look at `scipy.ndimage.gaussian_filter` for that purpose. Make sure that your animation can loop endlessly, i.e. the last frames and the first frames of the animation also blend. The $\\sigma$ value of the gaussian filter defines how many frames are blended; use the given parameter values of the function to control this value.<br>\n",
    "Your output should look like this (or better):\n",
    "\n",
    "<img src='img/Faces_DCGAN_latent_walk_1.gif' style='margin: 0px 10px' align='left' width=\"128\">\n",
    "\n",
    "<img src='img/Faces_DCGAN_latent_walk_2.gif' style='margin: 0px 10px' align='left' width=\"128\">\n",
    "\n",
    "<img src='img/Faces_DCGAN_latent_walk_3.gif' style='margin: 0px 10px' align='left' width=\"128\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_walk(duration_sec=20.0, smoothing_sec=1.0, fps=30):\n",
    "    #######################################################################################################\n",
    "    # TODO 8: create a smoothly interpolated loop through random latent space values\n",
    "    #######################################################################################################\n",
    "    \n",
    "    images = None #TODO create smoothly interpolating images\n",
    "    \n",
    "    imageio.mimsave(result_dir + '/latent_space_walk.gif', images, fps=fps)\n",
    "\n",
    "generate_latent_walk()       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4B: Conditional DCGAN\n",
    "\n",
    "Our previous Generator network was generating random outputs for each input latent vector without any measure of control over the output. \n",
    "Now, we would like to add some control mechanism such that we can determine the class for a generated image, e.g. generate only the number $5$ or images from the category $Shirt$.\n",
    "\n",
    "The expected output of this GAN should look like this (or better):\n",
    "\n",
    "<img src=\"img/cond_DCGAN_MNIST.png\" align='left' width=\"550\">\n",
    "<img src=\"img/cond_DCGAN_fashionMNIST.png\" align='left' width=\"550\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, we will use either _MNIST_ or _FashionMNIST_ at $32\\times32$ grayscale for this exercise again.\n",
    "\n",
    "For a class-conditioned output, we need to modify both the generator as well as the discriminator network to accept a class label as part of the input. These labels need to be transformed from a \"categorical\" input to a numerical vector. Use `torch.nn.Embedding` to transform the label to such an embedding space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Modify Networks for conditional GANs (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select appropriate training hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: choose reasonable values\n",
    "batch_size = 0\n",
    "num_epochs = 0\n",
    "learning_rate = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Design a conditional discriminator network (8 points)\n",
    "\n",
    "Below diagrams shows the architecture that you're expected to implement\n",
    "\n",
    "<img src=\"img/DCGAN_discriminator_conditional.png\" align='left' width=\"900\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "#TODO 9: update the discriminator network to incorporate the label input\n",
    "#######################################################################################################\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_classes=10):\n",
    "        super().__init__()\n",
    "        pass # TODO\n",
    "    \n",
    "    def forward(self, input, labels):\n",
    "        # TODO implement forward pass\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Design a conditional generator network (8 points)\n",
    "\n",
    "<img src=\"img/DCGAN_generator_conditional.png\" align='left' width=\"900\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "#TODO 10: update the generator network to incorporate the label input\n",
    "#######################################################################################################\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, n_classes=10):\n",
    "        super().__init__()\n",
    "        pass # TODO\n",
    "    \n",
    "    def forward(self, input, labels):\n",
    "        # TODO implement forward pass   \n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete the output function (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output generated samples from the current state of the generator network\n",
    "n_samples = 5\n",
    "\n",
    "#######################################################################################################\n",
    "# TODO 11: generate a fixed noise vector and a fixed set of labels to evaluate the output of the generator\n",
    "# with the same noise parameters as training progresses.\n",
    "# Arrange the labels into a grid to show same label outputs in the same column (see example results above) \n",
    "#######################################################################################################\n",
    "fixed_z = None\n",
    "fixed_labels = None\n",
    "\n",
    "def show_conditional_result(num_epoch, show=False, save=False, n_classes=10, n_samples=5, path='result.png', useFixed=False):\n",
    "    with torch.no_grad():\n",
    "        if useFixed:   \n",
    "            fake = G(fixed_z, fixed_labels).cpu()\n",
    "        else:\n",
    "            # TODO generate a new random noise vector and a grid of labels\n",
    "            z = None\n",
    "            labels = None\n",
    "\n",
    "            fake = G(z, labels).cpu()\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(20, 10))\n",
    "        image = utils.make_grid(fake.data, n_classes, 1)\n",
    "\n",
    "        plt.imshow(np.transpose(image, (1, 2, 0)))\n",
    "\n",
    "        ax.axis('off')\n",
    "\n",
    "        plt.savefig(path)\n",
    "\n",
    "        if show:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete the training setup (5 points) and training loop (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "\n",
    "# define dataloader\n",
    "data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "result_dir = '{}_conditional_DCGAN'.format(dset_name)\n",
    "\n",
    "# results save folder\n",
    "if not os.path.isdir(result_dir):\n",
    "    os.mkdir(result_dir)\n",
    "    \n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "#######################################################################################################\n",
    "# TODO 12: define training setup\n",
    "#######################################################################################################\n",
    "\n",
    "# TODO define networks\n",
    "G = None\n",
    "D = None\n",
    "\n",
    "# TODO define optimizers\n",
    "G_optimizer = None\n",
    "D_optimizer = None \n",
    "\n",
    "progress = {}\n",
    "progress['D_losses'] = []\n",
    "progress['G_losses'] = []\n",
    "progress['per_epoch_times'] = []\n",
    "progress['total_time'] = []\n",
    "num_iter = 0\n",
    "\n",
    "# start training loop\n",
    "print('Training ...')\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    D_losses = []\n",
    "    G_losses = []\n",
    "    \n",
    "    epoch_start_time = time.time()\n",
    "    num_batches = 0\n",
    "    \n",
    "    for real, real_labels in data_loader:\n",
    "        \n",
    "        #######################################################################################################\n",
    "        # TODO 13: Fill code for training loop\n",
    "        #######################################################################################################\n",
    "\n",
    "        # generate random latent vector z and random class assignments for each generated image in the minibatch as well as real and fake labels \n",
    "    \n",
    "        # TODO \n",
    "        \n",
    "        # generate fakes    \n",
    "\n",
    "        # TODO \n",
    "        \n",
    "        # evaluate fakes\n",
    "        \n",
    "        # TODO \n",
    "\n",
    "        # evaluate real minibatch\n",
    "         \n",
    "        # TODO\n",
    "        \n",
    "        # accumulate discriminator loss from the information about the real and fake images it just saw\n",
    "        \n",
    "        D_train_loss = None         \n",
    "\n",
    "        # train discriminator D step\n",
    "        D.zero_grad()\n",
    "        D_train_loss.backward()\n",
    "        D_optimizer.step() \n",
    "        \n",
    "        # train generator to output an image that is classified as real              \n",
    "        G_train_loss = None     \n",
    "        \n",
    "        # train generator G step\n",
    "        G.zero_grad()\n",
    "        G_train_loss.backward()\n",
    "        G_optimizer.step()              \n",
    "\n",
    "        D_losses.append(D_train_loss.data.item())\n",
    "        G_losses.append(G_train_loss.data.item())\n",
    "        \n",
    "        epoch_end_time = time.time()\n",
    "    per_epoch_time = epoch_end_time - epoch_start_time\n",
    "    \n",
    "    print('Epoch [{} / {}] G loss: {} D loss: {}'.format(epoch + 1, num_epochs, G_train_loss, D_train_loss))\n",
    "\n",
    "    show_conditional_result( epoch, save=True, show=True, path=result_dir + '/{}_conditional_DCGAN_{}.png'.format(dset_name, epoch), useFixed=True )\n",
    "    progress['D_losses'].append(torch.mean(torch.FloatTensor(D_losses)))\n",
    "    progress['G_losses'].append(torch.mean(torch.FloatTensor(G_losses)))\n",
    "    progress['per_epoch_times'].append(per_epoch_time)\n",
    "     \n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "progress['total_time'].append(total_time)\n",
    "\n",
    "print('Avg per epoch time: {:.2f} sec, total {:d} epochs time: {:.2f} min'.format(torch.mean(torch.FloatTensor(progress['per_epoch_times'])), num_epochs, total_time / 60))\n",
    "print('Training finished!')\n",
    "print('...saving training results')\n",
    "\n",
    "torch.save(G.state_dict(), result_dir + '/generator_network.pkl')\n",
    "torch.save(D.state_dict(), result_dir + '/discriminator_network.pkl')\n",
    "with open(result_dir + '/progress.pkl', 'wb') as f:\n",
    "    pickle.dump(progress, f)\n",
    "\n",
    "# plot loss curves\n",
    "plot_losses(progress, save=True, path=result_dir + '/{}_DCGAN_progress.png'.format(dset_name))\n",
    "\n",
    "# show training progress as animation\n",
    "images = []\n",
    "for e in range(num_epochs):\n",
    "    img_name = result_dir + '/{}_conditional_DCGAN_{}.png'.format(dset_name, e)\n",
    "    images.append(imageio.imread(img_name))\n",
    "imageio.mimsave(result_dir + '/conditional_DCGAN_generation_animation.gif', images, fps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the animated generation GIF\n",
    "\n",
    "% **TODO: edit path to GIF** %\n",
    "\n",
    "<img src='full_path_to_gif.gif' width=\"512\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
